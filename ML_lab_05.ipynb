{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x1, x2\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3], [5,3], [6,2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W)+ b) #n by 1 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y * tf.log(hypo) 보면 n x 1 * n x 1 인데 곱해지네?\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype= tf.float32) # n x 1 matrix\n",
    "# 내부 부등호에서 리턴이 true or false로 되는데 이거를 float32로 캐스팅을 하면\n",
    "# true는 1이 되고, false는 0 이 됨. -> predicted가 담김. \n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype= tf.float32))\n",
    "#예측한 값과 똑같은지를확인시키면, true/false 나오고 1, 0으로 나옴. 그거를 평균을 구하면\n",
    "#accuracy가 나오지\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6489679\n",
      "200 0.50593776\n",
      "400 0.45112792\n",
      "600 0.42050123\n",
      "800 0.39964387\n",
      "1000 0.38333842\n",
      "1200 0.3694595\n",
      "1400 0.35705173\n",
      "1600 0.34564975\n",
      "1800 0.3350098\n",
      "2000 0.32499436\n",
      "2200 0.31551948\n",
      "2400 0.306529\n",
      "2600 0.29798204\n",
      "2800 0.28984636\n",
      "3000 0.28209496\n",
      "3200 0.27470395\n",
      "3400 0.26765183\n",
      "3600 0.26091895\n",
      "3800 0.25448683\n",
      "4000 0.2483384\n",
      "4200 0.24245769\n",
      "4400 0.23682952\n",
      "4600 0.23143996\n",
      "4800 0.22627555\n",
      "5000 0.22132404\n",
      "5200 0.21657376\n",
      "5400 0.21201368\n",
      "5600 0.20763361\n",
      "5800 0.20342402\n",
      "6000 0.19937576\n",
      "6200 0.19548045\n",
      "6400 0.19173016\n",
      "6600 0.18811746\n",
      "6800 0.18463534\n",
      "7000 0.18127728\n",
      "7200 0.17803717\n",
      "7400 0.1749091\n",
      "7600 0.1718877\n",
      "7800 0.16896786\n",
      "8000 0.16614468\n",
      "8200 0.16341378\n",
      "8400 0.16077076\n",
      "8600 0.15821156\n",
      "8800 0.15573253\n",
      "9000 0.15333007\n",
      "9200 0.1510007\n",
      "9400 0.14874123\n",
      "9600 0.1465488\n",
      "9800 0.1444203\n",
      "10000 0.14235328\n",
      "\n",
      "Hypothesis:  [[0.02779404]\n",
      " [0.15465166]\n",
      " [0.29044324]\n",
      " [0.78805107]\n",
      " [0.9436999 ]\n",
      " [0.98156196]] \n",
      "Correct (Y) :  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 ==0:\n",
    "            print(step, cost_val)\n",
    "        \n",
    "    #Accuracy Report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                      feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y) : \", c, \"\\nAccuracy: \", a)\n",
    "\n",
    "#for 문 돌면서 학습 한거고, \n",
    "#마지막에 w, b나와있겠지?\n",
    "#그거로 for문 종료 후에, hypothesis, predicted, accuracy를 실행 \n",
    "#hypothesis에는 기존 w, b에다가 내 데이터를 던지면서 그거로 h(x)계산하고 predicted\n",
    "#에서는 그거 받아서 0.5보다 크면 1, 0.5보다 작으면 0 으로 만들어 주고, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/data-03-diabetes.csv', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 8])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([8,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis >0.5, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype= tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0512977\n",
      "200 0.7625613\n",
      "400 0.7071938\n",
      "600 0.6840641\n",
      "800 0.6669105\n",
      "1000 0.6520201\n",
      "1200 0.6386954\n",
      "1400 0.6266937\n",
      "1600 0.61585563\n",
      "1800 0.60604835\n",
      "2000 0.59715503\n",
      "2200 0.58907306\n",
      "2400 0.5817123\n",
      "2600 0.5749935\n",
      "2800 0.56884724\n",
      "3000 0.5632127\n",
      "3200 0.5580363\n",
      "3400 0.5532713\n",
      "3600 0.54887617\n",
      "3800 0.54481465\n",
      "4000 0.5410544\n",
      "4200 0.5375671\n",
      "4400 0.5343274\n",
      "4600 0.53131294\n",
      "4800 0.52850354\n",
      "5000 0.5258816\n",
      "5200 0.5234308\n",
      "5400 0.5211371\n",
      "5600 0.5189876\n",
      "5800 0.5169706\n",
      "6000 0.5150756\n",
      "6200 0.5132932\n",
      "6400 0.51161486\n",
      "6600 0.5100327\n",
      "6800 0.5085397\n",
      "7000 0.5071293\n",
      "7200 0.50579596\n",
      "7400 0.5045339\n",
      "7600 0.50333834\n",
      "7800 0.50220484\n",
      "8000 0.5011292\n",
      "8200 0.5001076\n",
      "8400 0.49913663\n",
      "8600 0.49821296\n",
      "8800 0.4973336\n",
      "9000 0.4964959\n",
      "9200 0.49569726\n",
      "9400 0.49493527\n",
      "9600 0.4942079\n",
      "9800 0.4935129\n",
      "10000 0.49284852\n",
      "\n",
      "Hypothesis:  [[0.44794792]\n",
      " [0.92050946]\n",
      " [0.2462452 ]\n",
      " [0.94486064]\n",
      " [0.25115752]\n",
      " [0.7217667 ]\n",
      " [0.94941324]\n",
      " [0.64007187]\n",
      " [0.3306549 ]\n",
      " [0.44065833]\n",
      " [0.6237553 ]\n",
      " [0.19419064]\n",
      " [0.20469357]\n",
      " [0.4377657 ]\n",
      " [0.7421892 ]\n",
      " [0.42149836]\n",
      " [0.69530535]\n",
      " [0.9311575 ]\n",
      " [0.81506824]\n",
      " [0.5155042 ]\n",
      " [0.61233455]\n",
      " [0.10770066]\n",
      " [0.6113674 ]\n",
      " [0.6917782 ]\n",
      " [0.3935652 ]\n",
      " [0.9272893 ]\n",
      " [0.52613294]\n",
      " [0.5512985 ]\n",
      " [0.7200841 ]\n",
      " [0.4223754 ]\n",
      " [0.95380366]\n",
      " [0.7698535 ]\n",
      " [0.5552618 ]\n",
      " [0.81119716]\n",
      " [0.35372958]\n",
      " [0.6163183 ]\n",
      " [0.82147443]\n",
      " [0.5162026 ]\n",
      " [0.5452655 ]\n",
      " [0.33347192]\n",
      " [0.7686883 ]\n",
      " [0.12393607]\n",
      " [0.45256388]\n",
      " [0.07110768]\n",
      " [0.63797307]\n",
      " [0.9150332 ]\n",
      " [0.74187934]\n",
      " [0.7303034 ]\n",
      " [0.90895003]\n",
      " [0.943325  ]\n",
      " [0.9218678 ]\n",
      " [0.22867312]\n",
      " [0.40000823]\n",
      " [0.9737524 ]\n",
      " [0.28333247]\n",
      " [0.37880617]\n",
      " [0.10931099]\n",
      " [0.73836184]\n",
      " [0.88406515]\n",
      " [0.51207757]\n",
      " [0.933008  ]\n",
      " [0.7306377 ]\n",
      " [0.68021315]\n",
      " [0.8390543 ]\n",
      " [0.50930345]\n",
      " [0.50722104]\n",
      " [0.94965637]\n",
      " [0.64802444]\n",
      " [0.85040116]\n",
      " [0.6854999 ]\n",
      " [0.22903349]\n",
      " [0.68811595]\n",
      " [0.89947915]\n",
      " [0.94605446]\n",
      " [0.83783716]\n",
      " [0.787125  ]\n",
      " [0.5002213 ]\n",
      " [0.86806226]\n",
      " [0.93101966]\n",
      " [0.9184334 ]\n",
      " [0.81921864]\n",
      " [0.8187953 ]\n",
      " [0.28722733]\n",
      " [0.788083  ]\n",
      " [0.5337271 ]\n",
      " [0.87772286]\n",
      " [0.46241787]\n",
      " [0.9002519 ]\n",
      " [0.941243  ]\n",
      " [0.7537362 ]\n",
      " [0.79569113]\n",
      " [0.66215485]\n",
      " [0.6819355 ]\n",
      " [0.6173483 ]\n",
      " [0.91262865]\n",
      " [0.977777  ]\n",
      " [0.9073689 ]\n",
      " [0.5588311 ]\n",
      " [0.26367167]\n",
      " [0.688607  ]\n",
      " [0.49220496]\n",
      " [0.94915164]\n",
      " [0.7619964 ]\n",
      " [0.8060948 ]\n",
      " [0.7045547 ]\n",
      " [0.75108695]\n",
      " [0.9267388 ]\n",
      " [0.7703168 ]\n",
      " [0.5323628 ]\n",
      " [0.44995683]\n",
      " [0.9125396 ]\n",
      " [0.8681209 ]\n",
      " [0.5298554 ]\n",
      " [0.38231272]\n",
      " [0.6302526 ]\n",
      " [0.8591983 ]\n",
      " [0.87609375]\n",
      " [0.9111969 ]\n",
      " [0.16000916]\n",
      " [0.74677694]\n",
      " [0.8346211 ]\n",
      " [0.61469626]\n",
      " [0.5892605 ]\n",
      " [0.90833646]\n",
      " [0.728994  ]\n",
      " [0.86265457]\n",
      " [0.775187  ]\n",
      " [0.5378486 ]\n",
      " [0.56831753]\n",
      " [0.44455874]\n",
      " [0.5073621 ]\n",
      " [0.7670259 ]\n",
      " [0.91993976]\n",
      " [0.87133473]\n",
      " [0.7813362 ]\n",
      " [0.8484639 ]\n",
      " [0.39211574]\n",
      " [0.8045836 ]\n",
      " [0.70249546]\n",
      " [0.71460736]\n",
      " [0.9061535 ]\n",
      " [0.64664674]\n",
      " [0.63737583]\n",
      " [0.7006507 ]\n",
      " [0.8802417 ]\n",
      " [0.7213678 ]\n",
      " [0.48304155]\n",
      " [0.92787427]\n",
      " [0.625574  ]\n",
      " [0.7665783 ]\n",
      " [0.22604817]\n",
      " [0.3803977 ]\n",
      " [0.15688269]\n",
      " [0.25367907]\n",
      " [0.9307618 ]\n",
      " [0.88172126]\n",
      " [0.9291546 ]\n",
      " [0.13064773]\n",
      " [0.4656446 ]\n",
      " [0.76808316]\n",
      " [0.6055105 ]\n",
      " [0.8868316 ]\n",
      " [0.33122852]\n",
      " [0.7838627 ]\n",
      " [0.6704791 ]\n",
      " [0.6277471 ]\n",
      " [0.7229134 ]\n",
      " [0.81034917]\n",
      " [0.7138784 ]\n",
      " [0.64266014]\n",
      " [0.8868297 ]\n",
      " [0.88401973]\n",
      " [0.9472895 ]\n",
      " [0.24194936]\n",
      " [0.7733299 ]\n",
      " [0.19685064]\n",
      " [0.43486616]\n",
      " [0.35700265]\n",
      " [0.83226913]\n",
      " [0.6867499 ]\n",
      " [0.9171583 ]\n",
      " [0.9006269 ]\n",
      " [0.5903412 ]\n",
      " [0.1976638 ]\n",
      " [0.2546645 ]\n",
      " [0.43951014]\n",
      " [0.67347664]\n",
      " [0.5952465 ]\n",
      " [0.8439674 ]\n",
      " [0.614196  ]\n",
      " [0.40190408]\n",
      " [0.30150214]\n",
      " [0.9180972 ]\n",
      " [0.37140635]\n",
      " [0.8840072 ]\n",
      " [0.8935638 ]\n",
      " [0.70597   ]\n",
      " [0.7172742 ]\n",
      " [0.59455186]\n",
      " [0.55635566]\n",
      " [0.7001868 ]\n",
      " [0.93544745]\n",
      " [0.78184897]\n",
      " [0.79034215]\n",
      " [0.17827214]\n",
      " [0.2586321 ]\n",
      " [0.91754395]\n",
      " [0.2277606 ]\n",
      " [0.93779856]\n",
      " [0.25578716]\n",
      " [0.255009  ]\n",
      " [0.54035956]\n",
      " [0.66460836]\n",
      " [0.2435348 ]\n",
      " [0.76451105]\n",
      " [0.7221637 ]\n",
      " [0.75871384]\n",
      " [0.7037506 ]\n",
      " [0.21942364]\n",
      " [0.31471255]\n",
      " [0.72651815]\n",
      " [0.59443116]\n",
      " [0.9141206 ]\n",
      " [0.9215101 ]\n",
      " [0.660749  ]\n",
      " [0.49430227]\n",
      " [0.04271415]\n",
      " [0.6485646 ]\n",
      " [0.32474667]\n",
      " [0.49610186]\n",
      " [0.9201749 ]\n",
      " [0.6487679 ]\n",
      " [0.9386025 ]\n",
      " [0.27526546]\n",
      " [0.13893113]\n",
      " [0.2583893 ]\n",
      " [0.6672416 ]\n",
      " [0.9263494 ]\n",
      " [0.8637656 ]\n",
      " [0.69613343]\n",
      " [0.7072014 ]\n",
      " [0.6068228 ]\n",
      " [0.14585659]\n",
      " [0.5655385 ]\n",
      " [0.14862816]\n",
      " [0.6030532 ]\n",
      " [0.83746415]\n",
      " [0.72829974]\n",
      " [0.63962024]\n",
      " [0.92963254]\n",
      " [0.8105061 ]\n",
      " [0.7752589 ]\n",
      " [0.79924154]\n",
      " [0.8009425 ]\n",
      " [0.8690684 ]\n",
      " [0.538171  ]\n",
      " [0.5039728 ]\n",
      " [0.54853034]\n",
      " [0.8001299 ]\n",
      " [0.69537157]\n",
      " [0.7225749 ]\n",
      " [0.7859527 ]\n",
      " [0.35572383]\n",
      " [0.5237093 ]\n",
      " [0.62527376]\n",
      " [0.6706919 ]\n",
      " [0.35792953]\n",
      " [0.91348743]\n",
      " [0.7209553 ]\n",
      " [0.90404576]\n",
      " [0.5640816 ]\n",
      " [0.75333214]\n",
      " [0.83391726]\n",
      " [0.81465364]\n",
      " [0.636592  ]\n",
      " [0.86268604]\n",
      " [0.3832862 ]\n",
      " [0.58614045]\n",
      " [0.6415783 ]\n",
      " [0.3395081 ]\n",
      " [0.7774508 ]\n",
      " [0.28448275]\n",
      " [0.56443745]\n",
      " [0.9385056 ]\n",
      " [0.7724704 ]\n",
      " [0.79683524]\n",
      " [0.7033107 ]\n",
      " [0.46496075]\n",
      " [0.74715465]\n",
      " [0.53184444]\n",
      " [0.5202183 ]\n",
      " [0.6576321 ]\n",
      " [0.55226845]\n",
      " [0.62094206]\n",
      " [0.5759727 ]\n",
      " [0.24923201]\n",
      " [0.73661417]\n",
      " [0.87260276]\n",
      " [0.43530032]\n",
      " [0.59940267]\n",
      " [0.76152796]\n",
      " [0.5144045 ]\n",
      " [0.7530624 ]\n",
      " [0.47791475]\n",
      " [0.7092559 ]\n",
      " [0.8930345 ]\n",
      " [0.64733964]\n",
      " [0.69664866]\n",
      " [0.8949371 ]\n",
      " [0.5027045 ]\n",
      " [0.8623898 ]\n",
      " [0.918047  ]\n",
      " [0.32868195]\n",
      " [0.80871016]\n",
      " [0.2750359 ]\n",
      " [0.8102359 ]\n",
      " [0.8038444 ]\n",
      " [0.71166575]\n",
      " [0.27065018]\n",
      " [0.8060894 ]\n",
      " [0.75215906]\n",
      " [0.76901436]\n",
      " [0.22824827]\n",
      " [0.7875071 ]\n",
      " [0.84537303]\n",
      " [0.5212093 ]\n",
      " [0.950671  ]\n",
      " [0.38950077]\n",
      " [0.6245878 ]\n",
      " [0.9488852 ]\n",
      " [0.26248854]\n",
      " [0.50160146]\n",
      " [0.6631626 ]\n",
      " [0.30758676]\n",
      " [0.19137923]\n",
      " [0.8401399 ]\n",
      " [0.89556175]\n",
      " [0.8542067 ]\n",
      " [0.55840373]\n",
      " [0.6676528 ]\n",
      " [0.5294128 ]\n",
      " [0.83707356]\n",
      " [0.81580025]\n",
      " [0.9308192 ]\n",
      " [0.72928345]\n",
      " [0.73867714]\n",
      " [0.5332294 ]\n",
      " [0.91850704]\n",
      " [0.939081  ]\n",
      " [0.72131526]\n",
      " [0.24530636]\n",
      " [0.7484473 ]\n",
      " [0.44236293]\n",
      " [0.72699976]\n",
      " [0.23303038]\n",
      " [0.31963018]\n",
      " [0.4866046 ]\n",
      " [0.5838594 ]\n",
      " [0.41519105]\n",
      " [0.5957316 ]\n",
      " [0.87082714]\n",
      " [0.6222002 ]\n",
      " [0.86162776]\n",
      " [0.91654265]\n",
      " [0.66564655]\n",
      " [0.07490539]\n",
      " [0.4711548 ]\n",
      " [0.85367703]\n",
      " [0.87898535]\n",
      " [0.7381245 ]\n",
      " [0.28378054]\n",
      " [0.8321023 ]\n",
      " [0.9017121 ]\n",
      " [0.36267528]\n",
      " [0.45794275]\n",
      " [0.81269675]\n",
      " [0.827239  ]\n",
      " [0.8840007 ]\n",
      " [0.88642365]\n",
      " [0.8663092 ]\n",
      " [0.9340281 ]\n",
      " [0.66982865]\n",
      " [0.52829254]\n",
      " [0.5570814 ]\n",
      " [0.8194519 ]\n",
      " [0.88458526]\n",
      " [0.27731928]\n",
      " [0.84491277]\n",
      " [0.86032414]\n",
      " [0.31180567]\n",
      " [0.62721133]\n",
      " [0.8653285 ]\n",
      " [0.585157  ]\n",
      " [0.8809329 ]\n",
      " [0.3512202 ]\n",
      " [0.8386825 ]\n",
      " [0.57860464]\n",
      " [0.849693  ]\n",
      " [0.44763115]\n",
      " [0.80037105]\n",
      " [0.709727  ]\n",
      " [0.7686865 ]\n",
      " [0.09926485]\n",
      " [0.2921853 ]\n",
      " [0.5814279 ]\n",
      " [0.81043607]\n",
      " [0.4378792 ]\n",
      " [0.7965963 ]\n",
      " [0.5723625 ]\n",
      " [0.36827022]\n",
      " [0.8239514 ]\n",
      " [0.46018565]\n",
      " [0.88897675]\n",
      " [0.8277444 ]\n",
      " [0.62163246]\n",
      " [0.91455555]\n",
      " [0.69847524]\n",
      " [0.83672583]\n",
      " [0.36271298]\n",
      " [0.31836468]\n",
      " [0.76175624]\n",
      " [0.5380127 ]\n",
      " [0.3784131 ]\n",
      " [0.881387  ]\n",
      " [0.891371  ]\n",
      " [0.8974661 ]\n",
      " [0.9368233 ]\n",
      " [0.6673762 ]\n",
      " [0.87843215]\n",
      " [0.46049544]\n",
      " [0.3516593 ]\n",
      " [0.4631057 ]\n",
      " [0.93892926]\n",
      " [0.50086004]\n",
      " [0.13822506]\n",
      " [0.92250407]\n",
      " [0.8321465 ]\n",
      " [0.5326365 ]\n",
      " [0.8371905 ]\n",
      " [0.02053731]\n",
      " [0.9038526 ]\n",
      " [0.7103561 ]\n",
      " [0.74704754]\n",
      " [0.7472623 ]\n",
      " [0.9584157 ]\n",
      " [0.620395  ]\n",
      " [0.7769303 ]\n",
      " [0.7484695 ]\n",
      " [0.886606  ]\n",
      " [0.27132213]\n",
      " [0.7079    ]\n",
      " [0.8951622 ]\n",
      " [0.61755806]\n",
      " [0.70886874]\n",
      " [0.93058103]\n",
      " [0.81645554]\n",
      " [0.8551076 ]\n",
      " [0.32516262]\n",
      " [0.82262826]\n",
      " [0.94824344]\n",
      " [0.7469668 ]\n",
      " [0.6802348 ]\n",
      " [0.33533776]\n",
      " [0.46737435]\n",
      " [0.54915255]\n",
      " [0.662958  ]\n",
      " [0.45798075]\n",
      " [0.78420544]\n",
      " [0.5553649 ]\n",
      " [0.72112143]\n",
      " [0.79125345]\n",
      " [0.7100236 ]\n",
      " [0.62038565]\n",
      " [0.5559824 ]\n",
      " [0.52444404]\n",
      " [0.9380841 ]\n",
      " [0.79731375]\n",
      " [0.33485264]\n",
      " [0.48384175]\n",
      " [0.61643803]\n",
      " [0.13741235]\n",
      " [0.8763716 ]\n",
      " [0.16117449]\n",
      " [0.89725   ]\n",
      " [0.83311135]\n",
      " [0.839118  ]\n",
      " [0.6752474 ]\n",
      " [0.8920666 ]\n",
      " [0.39330843]\n",
      " [0.7568249 ]\n",
      " [0.92572355]\n",
      " [0.37194905]\n",
      " [0.43087485]\n",
      " [0.82782865]\n",
      " [0.86936814]\n",
      " [0.6711909 ]\n",
      " [0.81539565]\n",
      " [0.80178046]\n",
      " [0.7389532 ]\n",
      " [0.26078498]\n",
      " [0.8068239 ]\n",
      " [0.9194301 ]\n",
      " [0.58554846]\n",
      " [0.77224225]\n",
      " [0.7528336 ]\n",
      " [0.79759204]\n",
      " [0.85376865]\n",
      " [0.9413478 ]\n",
      " [0.65104866]\n",
      " [0.3509204 ]\n",
      " [0.7840548 ]\n",
      " [0.6932275 ]\n",
      " [0.95553184]\n",
      " [0.7332748 ]\n",
      " [0.72779906]\n",
      " [0.42380792]\n",
      " [0.76088935]\n",
      " [0.92970467]\n",
      " [0.9479569 ]\n",
      " [0.8816513 ]\n",
      " [0.69479376]\n",
      " [0.6308702 ]\n",
      " [0.82688916]\n",
      " [0.45631582]\n",
      " [0.80237395]\n",
      " [0.79616284]\n",
      " [0.8913319 ]\n",
      " [0.65754354]\n",
      " [0.6111955 ]\n",
      " [0.8817379 ]\n",
      " [0.43481553]\n",
      " [0.41809556]\n",
      " [0.64425904]\n",
      " [0.72639257]\n",
      " [0.59178334]\n",
      " [0.86480093]\n",
      " [0.90119016]\n",
      " [0.193237  ]\n",
      " [0.18482856]\n",
      " [0.7878744 ]\n",
      " [0.5199785 ]\n",
      " [0.15509278]\n",
      " [0.8537916 ]\n",
      " [0.88909256]\n",
      " [0.63379616]\n",
      " [0.93442315]\n",
      " [0.92100847]\n",
      " [0.7539066 ]\n",
      " [0.84681237]\n",
      " [0.66989017]\n",
      " [0.62618506]\n",
      " [0.7146357 ]\n",
      " [0.618573  ]\n",
      " [0.18282343]\n",
      " [0.8986538 ]\n",
      " [0.8849037 ]\n",
      " [0.63271534]\n",
      " [0.9238923 ]\n",
      " [0.8711746 ]\n",
      " [0.89656174]\n",
      " [0.6129163 ]\n",
      " [0.7201505 ]\n",
      " [0.8730327 ]\n",
      " [0.61680436]\n",
      " [0.86694324]\n",
      " [0.9239986 ]\n",
      " [0.5163221 ]\n",
      " [0.86800915]\n",
      " [0.8684287 ]\n",
      " [0.5494365 ]\n",
      " [0.52774394]\n",
      " [0.12020941]\n",
      " [0.25268146]\n",
      " [0.84649193]\n",
      " [0.6370376 ]\n",
      " [0.6658645 ]\n",
      " [0.5554209 ]\n",
      " [0.94288933]\n",
      " [0.50339764]\n",
      " [0.7912842 ]\n",
      " [0.2606603 ]\n",
      " [0.8719346 ]\n",
      " [0.3181648 ]\n",
      " [0.7520774 ]\n",
      " [0.5589921 ]\n",
      " [0.85571635]\n",
      " [0.56327987]\n",
      " [0.23735954]\n",
      " [0.78111565]\n",
      " [0.9711004 ]\n",
      " [0.4456606 ]\n",
      " [0.94802356]\n",
      " [0.81976885]\n",
      " [0.84272707]\n",
      " [0.8035921 ]\n",
      " [0.4333222 ]\n",
      " [0.4082111 ]\n",
      " [0.77196634]\n",
      " [0.19013259]\n",
      " [0.9406754 ]\n",
      " [0.3463962 ]\n",
      " [0.9303968 ]\n",
      " [0.9052962 ]\n",
      " [0.5414301 ]\n",
      " [0.18864486]\n",
      " [0.63387483]\n",
      " [0.46227065]\n",
      " [0.8054667 ]\n",
      " [0.57824904]\n",
      " [0.9747313 ]\n",
      " [0.47077954]\n",
      " [0.66554743]\n",
      " [0.7353131 ]\n",
      " [0.7207258 ]\n",
      " [0.06143393]\n",
      " [0.77784294]\n",
      " [0.830323  ]\n",
      " [0.77283776]\n",
      " [0.6380245 ]\n",
      " [0.45278493]\n",
      " [0.5912299 ]\n",
      " [0.9116332 ]\n",
      " [0.6217767 ]\n",
      " [0.7286071 ]\n",
      " [0.82010835]\n",
      " [0.8333802 ]\n",
      " [0.7908328 ]\n",
      " [0.5321434 ]\n",
      " [0.7734969 ]\n",
      " [0.8747641 ]\n",
      " [0.6679624 ]\n",
      " [0.94420093]\n",
      " [0.71269387]\n",
      " [0.6269791 ]\n",
      " [0.47939372]\n",
      " [0.8220626 ]\n",
      " [0.81585485]\n",
      " [0.5450956 ]\n",
      " [0.6640725 ]\n",
      " [0.36632174]\n",
      " [0.5013386 ]\n",
      " [0.827648  ]\n",
      " [0.95225495]\n",
      " [0.86187947]\n",
      " [0.7115919 ]\n",
      " [0.788436  ]\n",
      " [0.8866268 ]\n",
      " [0.6638432 ]\n",
      " [0.92865866]\n",
      " [0.5242999 ]\n",
      " [0.7669243 ]\n",
      " [0.29383615]\n",
      " [0.10412291]\n",
      " [0.20790963]\n",
      " [0.3299682 ]\n",
      " [0.7535532 ]\n",
      " [0.79158413]\n",
      " [0.6309149 ]\n",
      " [0.74302554]\n",
      " [0.84132034]\n",
      " [0.50530505]\n",
      " [0.44801024]\n",
      " [0.9220992 ]\n",
      " [0.79149175]\n",
      " [0.34010074]\n",
      " [0.62981516]\n",
      " [0.22618705]\n",
      " [0.343949  ]\n",
      " [0.7606652 ]\n",
      " [0.7846379 ]\n",
      " [0.9055344 ]\n",
      " [0.9741088 ]\n",
      " [0.24891037]\n",
      " [0.7472411 ]\n",
      " [0.55485296]\n",
      " [0.4349465 ]\n",
      " [0.71464044]\n",
      " [0.7264867 ]\n",
      " [0.9264565 ]\n",
      " [0.68680686]\n",
      " [0.5223971 ]\n",
      " [0.54586476]\n",
      " [0.10141391]\n",
      " [0.6800428 ]\n",
      " [0.56402457]\n",
      " [0.90363944]\n",
      " [0.5299171 ]\n",
      " [0.6007704 ]\n",
      " [0.7793912 ]\n",
      " [0.67182994]\n",
      " [0.48823774]\n",
      " [0.74292815]\n",
      " [0.6219407 ]\n",
      " [0.32349738]\n",
      " [0.68925476]\n",
      " [0.86678267]\n",
      " [0.8136699 ]\n",
      " [0.6240947 ]\n",
      " [0.8702157 ]\n",
      " [0.30764386]\n",
      " [0.8505074 ]\n",
      " [0.67611367]\n",
      " [0.7263832 ]\n",
      " [0.504078  ]\n",
      " [0.7251446 ]\n",
      " [0.81202066]\n",
      " [0.28220478]\n",
      " [0.29133058]\n",
      " [0.786276  ]\n",
      " [0.8341727 ]\n",
      " [0.79434323]\n",
      " [0.8701751 ]\n",
      " [0.8279837 ]\n",
      " [0.73281324]\n",
      " [0.69838625]\n",
      " [0.691807  ]\n",
      " [0.6982195 ]\n",
      " [0.77289814]\n",
      " [0.4447935 ]\n",
      " [0.36767152]\n",
      " [0.9031202 ]\n",
      " [0.7737328 ]\n",
      " [0.54176253]\n",
      " [0.28011343]\n",
      " [0.89406246]\n",
      " [0.7782391 ]\n",
      " [0.8606237 ]\n",
      " [0.596928  ]\n",
      " [0.8660548 ]\n",
      " [0.9003026 ]\n",
      " [0.7782233 ]\n",
      " [0.40108383]\n",
      " [0.9268915 ]\n",
      " [0.92416066]\n",
      " [0.24905752]\n",
      " [0.13179427]\n",
      " [0.64260364]\n",
      " [0.38650995]\n",
      " [0.7771146 ]\n",
      " [0.41682413]\n",
      " [0.51918274]\n",
      " [0.4021729 ]\n",
      " [0.7605652 ]\n",
      " [0.8795341 ]\n",
      " [0.15098026]\n",
      " [0.3921467 ]\n",
      " [0.5241418 ]\n",
      " [0.42916876]\n",
      " [0.545215  ]\n",
      " [0.7745064 ]\n",
      " [0.16619238]\n",
      " [0.91348267]\n",
      " [0.25161862]\n",
      " [0.8340375 ]\n",
      " [0.7033465 ]\n",
      " [0.75744843]\n",
      " [0.81474715]\n",
      " [0.7639133 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.8868722 ]] \n",
      "Correct (Y) :  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]] \n",
      "Accuracy:  0.7602108\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 200 ==0:\n",
    "            print(step, cost_val)\n",
    "        \n",
    "    #Accuracy Report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], \n",
    "                      feed_dict = {X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect (Y) : \", c, \"\\nAccuracy: \", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
