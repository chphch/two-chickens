{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [\n",
    "    [1, 2, 1],\n",
    "    [1, 3, 2],\n",
    "    [1, 3, 4],\n",
    "    [1, 5, 5],\n",
    "    [1, 7, 5],\n",
    "    [1, 2, 5],\n",
    "    [1, 6, 6],\n",
    "    [1, 7, 7],\n",
    "]\n",
    "y_data = [\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [1, 0, 0]\n",
    "]\n",
    "x_test = [\n",
    "    [2, 1, 1],\n",
    "    [3, 1, 2],\n",
    "    [3, 3, 4]\n",
    "]\n",
    "y_test = [\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1],\n",
    "    [0, 0, 1]\n",
    "]\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-10).minimize(cost)\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "1 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "2 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "3 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "4 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "5 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "6 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "7 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "8 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "9 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "10 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "11 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "12 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "13 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "14 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "15 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "16 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "17 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "18 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "19 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "20 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "21 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "22 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "23 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "24 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "25 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "26 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "27 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "28 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "29 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "30 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "31 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "32 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "33 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "34 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "35 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "36 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "37 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "38 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "39 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "40 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "41 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "42 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "43 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "44 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "45 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "46 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "47 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "48 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "49 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "50 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "51 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "52 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "53 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "54 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "55 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "56 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "57 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "58 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "59 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "60 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "61 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "62 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "63 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "64 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "65 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "66 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "67 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "68 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "69 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "70 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "71 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "72 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "73 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "74 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "75 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "76 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "77 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "78 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "79 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "80 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "81 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "82 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "83 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "84 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "85 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "86 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "87 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "88 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "89 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "90 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "91 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "92 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "93 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "94 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "95 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "96 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "97 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "98 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "99 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "100 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "101 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "102 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "103 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "104 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "105 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "106 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "107 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "108 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "109 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "110 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "111 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "112 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "113 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "114 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "115 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "116 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "117 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "118 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "119 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "120 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "121 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "122 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "123 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "124 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "125 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "126 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "127 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "128 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "129 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "130 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "131 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "132 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "133 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "134 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "135 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "136 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "137 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "138 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "139 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "140 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "141 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "142 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "143 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "144 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "145 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "146 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "147 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "148 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "149 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "150 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "151 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "152 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "153 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "154 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "155 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "156 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "157 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "159 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "160 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "161 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "162 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "163 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "164 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "165 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "166 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "167 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "168 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "169 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "170 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "171 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "172 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "173 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "174 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "175 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "176 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "177 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "178 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "179 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "180 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "181 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "182 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "183 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "184 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "185 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "186 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "187 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "188 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "189 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "190 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "191 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "192 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "193 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "194 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "195 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "196 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "197 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "198 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "199 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "200 4.039287 [[-0.7986747   0.3633462   0.72395426]\n",
      " [ 0.3533412   1.9682024   0.46550867]\n",
      " [ 0.20337589 -0.11129545 -0.1957373 ]]\n",
      "Prediction: [1 1 1]\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer],\n",
    "                                     feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  5.122214 \n",
      "Prediction:\n",
      " [[3.7113476]\n",
      " [4.4953547]\n",
      " [3.20588  ]\n",
      " [1.7762766]\n",
      " [2.5817213]\n",
      " [2.5394866]\n",
      " [1.1031953]\n",
      " [1.5169454]]\n",
      "1 Cost:  5.121834 \n",
      "Prediction:\n",
      " [[3.7112348]\n",
      " [4.4952435]\n",
      " [3.205788 ]\n",
      " [1.776206 ]\n",
      " [2.5816371]\n",
      " [2.5394053]\n",
      " [1.1031411]\n",
      " [1.5168912]]\n",
      "2 Cost:  5.121454 \n",
      "Prediction:\n",
      " [[3.711122 ]\n",
      " [4.4951324]\n",
      " [3.2056954]\n",
      " [1.7761353]\n",
      " [2.5815532]\n",
      " [2.539324 ]\n",
      " [1.1030867]\n",
      " [1.5168372]]\n",
      "3 Cost:  5.1210737 \n",
      "Prediction:\n",
      " [[3.7110095]\n",
      " [4.495021 ]\n",
      " [3.2056034]\n",
      " [1.7760648]\n",
      " [2.581469 ]\n",
      " [2.539243 ]\n",
      " [1.1030325]\n",
      " [1.5167831]]\n",
      "4 Cost:  5.1206937 \n",
      "Prediction:\n",
      " [[3.7108967]\n",
      " [4.49491  ]\n",
      " [3.2055116]\n",
      " [1.7759941]\n",
      " [2.5813851]\n",
      " [2.5391614]\n",
      " [1.1029782]\n",
      " [1.5167291]]\n",
      "5 Cost:  5.1203136 \n",
      "Prediction:\n",
      " [[3.710784 ]\n",
      " [4.4947987]\n",
      " [3.2054193]\n",
      " [1.7759236]\n",
      " [2.5813012]\n",
      " [2.5390804]\n",
      " [1.1029239]\n",
      " [1.516675 ]]\n",
      "6 Cost:  5.119934 \n",
      "Prediction:\n",
      " [[3.7106717]\n",
      " [4.4946876]\n",
      " [3.2053275]\n",
      " [1.775853 ]\n",
      " [2.5812173]\n",
      " [2.5389993]\n",
      " [1.1028696]\n",
      " [1.516621 ]]\n",
      "7 Cost:  5.1195545 \n",
      "Prediction:\n",
      " [[3.710559 ]\n",
      " [4.4945765]\n",
      " [3.2052352]\n",
      " [1.7757825]\n",
      " [2.5811334]\n",
      " [2.5389183]\n",
      " [1.1028153]\n",
      " [1.516567 ]]\n",
      "8 Cost:  5.1191745 \n",
      "Prediction:\n",
      " [[3.7104464]\n",
      " [4.4944654]\n",
      " [3.2051432]\n",
      " [1.7757119]\n",
      " [2.5810492]\n",
      " [2.538837 ]\n",
      " [1.102761 ]\n",
      " [1.516513 ]]\n",
      "9 Cost:  5.1187944 \n",
      "Prediction:\n",
      " [[3.7103336]\n",
      " [4.4943542]\n",
      " [3.2050512]\n",
      " [1.7756412]\n",
      " [2.5809653]\n",
      " [2.538756 ]\n",
      " [1.1027069]\n",
      " [1.516459 ]]\n",
      "10 Cost:  5.118415 \n",
      "Prediction:\n",
      " [[3.7102213]\n",
      " [4.494243 ]\n",
      " [3.2049592]\n",
      " [1.7755706]\n",
      " [2.5808814]\n",
      " [2.5386746]\n",
      " [1.1026525]\n",
      " [1.516405 ]]\n",
      "11 Cost:  5.1180353 \n",
      "Prediction:\n",
      " [[3.7101083]\n",
      " [4.494132 ]\n",
      " [3.204867 ]\n",
      " [1.7755002]\n",
      " [2.5807974]\n",
      " [2.5385935]\n",
      " [1.1025983]\n",
      " [1.516351 ]]\n",
      "12 Cost:  5.1176558 \n",
      "Prediction:\n",
      " [[3.709996 ]\n",
      " [4.494021 ]\n",
      " [3.2047749]\n",
      " [1.7754296]\n",
      " [2.5807135]\n",
      " [2.5385125]\n",
      " [1.1025441]\n",
      " [1.5162969]]\n",
      "13 Cost:  5.117276 \n",
      "Prediction:\n",
      " [[3.7098832]\n",
      " [4.4939094]\n",
      " [3.204683 ]\n",
      " [1.7753589]\n",
      " [2.5806293]\n",
      " [2.5384312]\n",
      " [1.1024898]\n",
      " [1.5162429]]\n",
      "14 Cost:  5.116897 \n",
      "Prediction:\n",
      " [[3.709771 ]\n",
      " [4.4937987]\n",
      " [3.204591 ]\n",
      " [1.7752885]\n",
      " [2.5805457]\n",
      " [2.53835  ]\n",
      " [1.1024356]\n",
      " [1.5161889]]\n",
      "15 Cost:  5.1165166 \n",
      "Prediction:\n",
      " [[3.7096581]\n",
      " [4.493687 ]\n",
      " [3.2044988]\n",
      " [1.775218 ]\n",
      " [2.5804615]\n",
      " [2.5382688]\n",
      " [1.1023813]\n",
      " [1.5161349]]\n",
      "16 Cost:  5.116137 \n",
      "Prediction:\n",
      " [[3.7095456]\n",
      " [4.493576 ]\n",
      " [3.2044067]\n",
      " [1.7751473]\n",
      " [2.5803773]\n",
      " [2.5381877]\n",
      " [1.102327 ]\n",
      " [1.5160809]]\n",
      "17 Cost:  5.1157575 \n",
      "Prediction:\n",
      " [[3.7094328]\n",
      " [4.493465 ]\n",
      " [3.2043147]\n",
      " [1.7750767]\n",
      " [2.5802937]\n",
      " [2.5381067]\n",
      " [1.1022727]\n",
      " [1.5160269]]\n",
      "18 Cost:  5.1153784 \n",
      "Prediction:\n",
      " [[3.7093205]\n",
      " [4.493354 ]\n",
      " [3.2042227]\n",
      " [1.7750062]\n",
      " [2.5802095]\n",
      " [2.5380254]\n",
      " [1.1022186]\n",
      " [1.5159729]]\n",
      "19 Cost:  5.114999 \n",
      "Prediction:\n",
      " [[3.7092075]\n",
      " [4.4932427]\n",
      " [3.2041306]\n",
      " [1.7749357]\n",
      " [2.5801258]\n",
      " [2.5379443]\n",
      " [1.1021643]\n",
      " [1.5159189]]\n",
      "20 Cost:  5.114619 \n",
      "Prediction:\n",
      " [[3.7090952]\n",
      " [4.4931316]\n",
      " [3.2040384]\n",
      " [1.774865 ]\n",
      " [2.5800416]\n",
      " [2.5378633]\n",
      " [1.10211  ]\n",
      " [1.5158648]]\n",
      "21 Cost:  5.1142387 \n",
      "Prediction:\n",
      " [[3.7089825]\n",
      " [4.4930205]\n",
      " [3.2039466]\n",
      " [1.7747945]\n",
      " [2.5799577]\n",
      " [2.5377817]\n",
      " [1.1020558]\n",
      " [1.5158108]]\n",
      "22 Cost:  5.11386 \n",
      "Prediction:\n",
      " [[3.7088702]\n",
      " [4.4929094]\n",
      " [3.2038543]\n",
      " [1.7747239]\n",
      " [2.5798738]\n",
      " [2.5377007]\n",
      " [1.1020015]\n",
      " [1.5157567]]\n",
      "23 Cost:  5.1134806 \n",
      "Prediction:\n",
      " [[3.7087574]\n",
      " [4.4927983]\n",
      " [3.2037623]\n",
      " [1.7746533]\n",
      " [2.5797896]\n",
      " [2.5376196]\n",
      " [1.1019473]\n",
      " [1.5157027]]\n",
      "24 Cost:  5.113101 \n",
      "Prediction:\n",
      " [[3.7086449]\n",
      " [4.492687 ]\n",
      " [3.2036703]\n",
      " [1.7745829]\n",
      " [2.5797057]\n",
      " [2.5375385]\n",
      " [1.101893 ]\n",
      " [1.5156488]]\n",
      "25 Cost:  5.1127214 \n",
      "Prediction:\n",
      " [[3.708532 ]\n",
      " [4.492576 ]\n",
      " [3.2035782]\n",
      " [1.7745124]\n",
      " [2.5796218]\n",
      " [2.5374572]\n",
      " [1.1018388]\n",
      " [1.5155948]]\n",
      "26 Cost:  5.1123424 \n",
      "Prediction:\n",
      " [[3.7084198]\n",
      " [4.492465 ]\n",
      " [3.2034862]\n",
      " [1.7744418]\n",
      " [2.5795379]\n",
      " [2.5373762]\n",
      " [1.1017846]\n",
      " [1.5155408]]\n",
      "27 Cost:  5.111963 \n",
      "Prediction:\n",
      " [[3.7083068]\n",
      " [4.492354 ]\n",
      " [3.2033942]\n",
      " [1.7743713]\n",
      " [2.579454 ]\n",
      " [2.537295 ]\n",
      " [1.1017303]\n",
      " [1.5154868]]\n",
      "28 Cost:  5.1115837 \n",
      "Prediction:\n",
      " [[3.7081945]\n",
      " [4.492243 ]\n",
      " [3.2033024]\n",
      " [1.7743008]\n",
      " [2.5793698]\n",
      " [2.5372138]\n",
      " [1.1016761]\n",
      " [1.5154328]]\n",
      "29 Cost:  5.111204 \n",
      "Prediction:\n",
      " [[3.7080817]\n",
      " [4.4921317]\n",
      " [3.20321  ]\n",
      " [1.7742302]\n",
      " [2.5792859]\n",
      " [2.5371327]\n",
      " [1.1016219]\n",
      " [1.515379 ]]\n",
      "30 Cost:  5.110826 \n",
      "Prediction:\n",
      " [[3.7079697]\n",
      " [4.492021 ]\n",
      " [3.2031183]\n",
      " [1.7741597]\n",
      " [2.5792022]\n",
      " [2.5370517]\n",
      " [1.1015676]\n",
      " [1.515325 ]]\n",
      "31 Cost:  5.110446 \n",
      "Prediction:\n",
      " [[3.707857 ]\n",
      " [4.4919095]\n",
      " [3.2030263]\n",
      " [1.7740892]\n",
      " [2.5791183]\n",
      " [2.5369709]\n",
      " [1.1015135]\n",
      " [1.515271 ]]\n",
      "32 Cost:  5.1100674 \n",
      "Prediction:\n",
      " [[3.7077444]\n",
      " [4.4917984]\n",
      " [3.2029343]\n",
      " [1.7740188]\n",
      " [2.5790343]\n",
      " [2.5368896]\n",
      " [1.1014593]\n",
      " [1.5152171]]\n",
      "33 Cost:  5.1096873 \n",
      "Prediction:\n",
      " [[3.7076316]\n",
      " [4.4916873]\n",
      " [3.2028422]\n",
      " [1.7739482]\n",
      " [2.5789502]\n",
      " [2.5368083]\n",
      " [1.101405 ]\n",
      " [1.515163 ]]\n",
      "34 Cost:  5.1093082 \n",
      "Prediction:\n",
      " [[3.7075193]\n",
      " [4.491576 ]\n",
      " [3.2027502]\n",
      " [1.7738775]\n",
      " [2.5788662]\n",
      " [2.5367272]\n",
      " [1.1013508]\n",
      " [1.515109 ]]\n",
      "35 Cost:  5.108929 \n",
      "Prediction:\n",
      " [[3.7074065]\n",
      " [4.4914656]\n",
      " [3.202658 ]\n",
      " [1.7738069]\n",
      " [2.5787823]\n",
      " [2.5366461]\n",
      " [1.1012965]\n",
      " [1.515055 ]]\n",
      "36 Cost:  5.10855 \n",
      "Prediction:\n",
      " [[3.7072942]\n",
      " [4.4913545]\n",
      " [3.202566 ]\n",
      " [1.7737365]\n",
      " [2.5786984]\n",
      " [2.5365648]\n",
      " [1.1012423]\n",
      " [1.515001 ]]\n",
      "37 Cost:  5.1081715 \n",
      "Prediction:\n",
      " [[3.7071815]\n",
      " [4.4912434]\n",
      " [3.2024739]\n",
      " [1.773666 ]\n",
      " [2.5786145]\n",
      " [2.5364838]\n",
      " [1.1011882]\n",
      " [1.514947 ]]\n",
      "38 Cost:  5.1077924 \n",
      "Prediction:\n",
      " [[3.7070694]\n",
      " [4.4911323]\n",
      " [3.202382 ]\n",
      " [1.7735955]\n",
      " [2.5785308]\n",
      " [2.5364027]\n",
      " [1.1011338]\n",
      " [1.514893 ]]\n",
      "39 Cost:  5.1074133 \n",
      "Prediction:\n",
      " [[3.7069564]\n",
      " [4.491021 ]\n",
      " [3.2022903]\n",
      " [1.7735249]\n",
      " [2.5784469]\n",
      " [2.5363219]\n",
      " [1.1010796]\n",
      " [1.514839 ]]\n",
      "40 Cost:  5.1070347 \n",
      "Prediction:\n",
      " [[3.706844 ]\n",
      " [4.49091  ]\n",
      " [3.2021983]\n",
      " [1.7734544]\n",
      " [2.5783627]\n",
      " [2.5362406]\n",
      " [1.1010256]\n",
      " [1.514785 ]]\n",
      "41 Cost:  5.106655 \n",
      "Prediction:\n",
      " [[3.7067313]\n",
      " [4.490799 ]\n",
      " [3.2021062]\n",
      " [1.7733841]\n",
      " [2.578279 ]\n",
      " [2.5361595]\n",
      " [1.1009712]\n",
      " [1.5147313]]\n",
      "42 Cost:  5.106277 \n",
      "Prediction:\n",
      " [[3.706619 ]\n",
      " [4.4906883]\n",
      " [3.2020142]\n",
      " [1.7733135]\n",
      " [2.578195 ]\n",
      " [2.5360785]\n",
      " [1.1009171]\n",
      " [1.5146773]]\n",
      "43 Cost:  5.105898 \n",
      "Prediction:\n",
      " [[3.7065063]\n",
      " [4.490577 ]\n",
      " [3.2019222]\n",
      " [1.773243 ]\n",
      " [2.5781112]\n",
      " [2.5359974]\n",
      " [1.100863 ]\n",
      " [1.5146235]]\n",
      "44 Cost:  5.10552 \n",
      "Prediction:\n",
      " [[3.7063942]\n",
      " [4.490466 ]\n",
      " [3.2018306]\n",
      " [1.7731725]\n",
      " [2.5780275]\n",
      " [2.5359163]\n",
      " [1.1008087]\n",
      " [1.5145695]]\n",
      "45 Cost:  5.1051407 \n",
      "Prediction:\n",
      " [[3.7062814]\n",
      " [4.4903555]\n",
      " [3.2017386]\n",
      " [1.7731022]\n",
      " [2.5779433]\n",
      " [2.5358353]\n",
      " [1.1007546]\n",
      " [1.5145156]]\n",
      "46 Cost:  5.104762 \n",
      "Prediction:\n",
      " [[3.7061691]\n",
      " [4.490245 ]\n",
      " [3.2016466]\n",
      " [1.7730316]\n",
      " [2.5778596]\n",
      " [2.5357542]\n",
      " [1.1007005]\n",
      " [1.5144618]]\n",
      "47 Cost:  5.1043835 \n",
      "Prediction:\n",
      " [[3.7060564]\n",
      " [4.490134 ]\n",
      " [3.2015548]\n",
      " [1.7729611]\n",
      " [2.5777757]\n",
      " [2.5356731]\n",
      " [1.1006463]\n",
      " [1.514408 ]]\n",
      "48 Cost:  5.104005 \n",
      "Prediction:\n",
      " [[3.705944 ]\n",
      " [4.4900227]\n",
      " [3.2014627]\n",
      " [1.7728904]\n",
      " [2.577692 ]\n",
      " [2.5355923]\n",
      " [1.1005921]\n",
      " [1.514354 ]]\n",
      "49 Cost:  5.1036263 \n",
      "Prediction:\n",
      " [[3.7058313]\n",
      " [4.4899116]\n",
      " [3.201371 ]\n",
      " [1.7728202]\n",
      " [2.577608 ]\n",
      " [2.535511 ]\n",
      " [1.100538 ]\n",
      " [1.5143001]]\n",
      "50 Cost:  5.1032476 \n",
      "Prediction:\n",
      " [[3.705719 ]\n",
      " [4.489801 ]\n",
      " [3.201279 ]\n",
      " [1.7727497]\n",
      " [2.5775242]\n",
      " [2.53543  ]\n",
      " [1.1004838]\n",
      " [1.5142462]]\n",
      "51 Cost:  5.1028695 \n",
      "Prediction:\n",
      " [[3.7056062]\n",
      " [4.4896903]\n",
      " [3.2011871]\n",
      " [1.7726792]\n",
      " [2.5774403]\n",
      " [2.535349 ]\n",
      " [1.1004297]\n",
      " [1.5141923]]\n",
      "52 Cost:  5.1024914 \n",
      "Prediction:\n",
      " [[3.7054942]\n",
      " [4.489579 ]\n",
      " [3.2010953]\n",
      " [1.7726086]\n",
      " [2.5773566]\n",
      " [2.535268 ]\n",
      " [1.1003755]\n",
      " [1.5141383]]\n",
      "53 Cost:  5.1021123 \n",
      "Prediction:\n",
      " [[3.7053814]\n",
      " [4.489468 ]\n",
      " [3.2010033]\n",
      " [1.7725382]\n",
      " [2.5772727]\n",
      " [2.535187 ]\n",
      " [1.1003213]\n",
      " [1.5140846]]\n",
      "54 Cost:  5.101734 \n",
      "Prediction:\n",
      " [[3.705269 ]\n",
      " [4.489357 ]\n",
      " [3.2009115]\n",
      " [1.7724677]\n",
      " [2.577189 ]\n",
      " [2.535106 ]\n",
      " [1.100267 ]\n",
      " [1.5140307]]\n",
      "55 Cost:  5.101355 \n",
      "Prediction:\n",
      " [[3.705156 ]\n",
      " [4.4892464]\n",
      " [3.2008195]\n",
      " [1.7723973]\n",
      " [2.5771048]\n",
      " [2.535025 ]\n",
      " [1.1002129]\n",
      " [1.5139768]]\n",
      "56 Cost:  5.100977 \n",
      "Prediction:\n",
      " [[3.705044 ]\n",
      " [4.4891353]\n",
      " [3.2007277]\n",
      " [1.7723267]\n",
      " [2.5770211]\n",
      " [2.5349438]\n",
      " [1.1001588]\n",
      " [1.5139228]]\n",
      "57 Cost:  5.1005983 \n",
      "Prediction:\n",
      " [[3.7049313]\n",
      " [4.4890246]\n",
      " [3.2006357]\n",
      " [1.7722563]\n",
      " [2.5769372]\n",
      " [2.5348628]\n",
      " [1.1001047]\n",
      " [1.513869 ]]\n",
      "58 Cost:  5.1002197 \n",
      "Prediction:\n",
      " [[3.704819 ]\n",
      " [4.4889135]\n",
      " [3.2005436]\n",
      " [1.7721859]\n",
      " [2.5768533]\n",
      " [2.5347815]\n",
      " [1.1000504]\n",
      " [1.513815 ]]\n",
      "59 Cost:  5.099841 \n",
      "Prediction:\n",
      " [[3.7047062]\n",
      " [4.4888024]\n",
      " [3.2004516]\n",
      " [1.7721153]\n",
      " [2.5767694]\n",
      " [2.5347004]\n",
      " [1.0999963]\n",
      " [1.5137613]]\n",
      "60 Cost:  5.099463 \n",
      "Prediction:\n",
      " [[3.7045941]\n",
      " [4.4886913]\n",
      " [3.20036  ]\n",
      " [1.7720449]\n",
      " [2.5766857]\n",
      " [2.5346196]\n",
      " [1.0999422]\n",
      " [1.5137074]]\n",
      "61 Cost:  5.0990844 \n",
      "Prediction:\n",
      " [[3.7044814]\n",
      " [4.4885807]\n",
      " [3.200268 ]\n",
      " [1.7719743]\n",
      " [2.5766017]\n",
      " [2.5345385]\n",
      " [1.0998881]\n",
      " [1.5136534]]\n",
      "62 Cost:  5.098707 \n",
      "Prediction:\n",
      " [[3.704369 ]\n",
      " [4.48847  ]\n",
      " [3.2001762]\n",
      " [1.7719039]\n",
      " [2.576518 ]\n",
      " [2.5344577]\n",
      " [1.0998338]\n",
      " [1.5135996]]\n",
      "63 Cost:  5.098328 \n",
      "Prediction:\n",
      " [[3.7042565]\n",
      " [4.488359 ]\n",
      " [3.2000842]\n",
      " [1.7718335]\n",
      " [2.5764341]\n",
      " [2.5343764]\n",
      " [1.0997797]\n",
      " [1.5135458]]\n",
      "64 Cost:  5.097951 \n",
      "Prediction:\n",
      " [[3.7041442]\n",
      " [4.4882483]\n",
      " [3.1999924]\n",
      " [1.7717631]\n",
      " [2.5763505]\n",
      " [2.5342956]\n",
      " [1.0997256]\n",
      " [1.5134919]]\n",
      "65 Cost:  5.0975723 \n",
      "Prediction:\n",
      " [[3.7040317]\n",
      " [4.4881372]\n",
      " [3.1999009]\n",
      " [1.7716926]\n",
      " [2.5762668]\n",
      " [2.5342147]\n",
      " [1.0996715]\n",
      " [1.513438 ]]\n",
      "66 Cost:  5.0971947 \n",
      "Prediction:\n",
      " [[3.7039194]\n",
      " [4.4880266]\n",
      " [3.1998088]\n",
      " [1.7716223]\n",
      " [2.5761826]\n",
      " [2.5341337]\n",
      " [1.0996174]\n",
      " [1.5133842]]\n",
      "67 Cost:  5.0968156 \n",
      "Prediction:\n",
      " [[3.7038066]\n",
      " [4.4879155]\n",
      " [3.1997168]\n",
      " [1.7715518]\n",
      " [2.5760987]\n",
      " [2.5340524]\n",
      " [1.0995632]\n",
      " [1.5133303]]\n",
      "68 Cost:  5.0964384 \n",
      "Prediction:\n",
      " [[3.7036946]\n",
      " [4.487805 ]\n",
      " [3.1996253]\n",
      " [1.7714815]\n",
      " [2.5760152]\n",
      " [2.5339715]\n",
      " [1.0995091]\n",
      " [1.5132763]]\n",
      "69 Cost:  5.09606 \n",
      "Prediction:\n",
      " [[3.7035818]\n",
      " [4.487694 ]\n",
      " [3.1995332]\n",
      " [1.771411 ]\n",
      " [2.5759313]\n",
      " [2.5338905]\n",
      " [1.099455 ]\n",
      " [1.5132226]]\n",
      "70 Cost:  5.095682 \n",
      "Prediction:\n",
      " [[3.7034698]\n",
      " [4.487583 ]\n",
      " [3.1994414]\n",
      " [1.7713405]\n",
      " [2.5758476]\n",
      " [2.5338097]\n",
      " [1.0994009]\n",
      " [1.5131688]]\n",
      "71 Cost:  5.0953035 \n",
      "Prediction:\n",
      " [[3.703357 ]\n",
      " [4.487472 ]\n",
      " [3.1993496]\n",
      " [1.7712702]\n",
      " [2.5757637]\n",
      " [2.5337284]\n",
      " [1.0993468]\n",
      " [1.5131149]]\n",
      "72 Cost:  5.094926 \n",
      "Prediction:\n",
      " [[3.7032447]\n",
      " [4.487361 ]\n",
      " [3.1992576]\n",
      " [1.7711997]\n",
      " [2.5756798]\n",
      " [2.5336475]\n",
      " [1.0992926]\n",
      " [1.513061 ]]\n",
      "73 Cost:  5.0945477 \n",
      "Prediction:\n",
      " [[3.7031322]\n",
      " [4.4872503]\n",
      " [3.1991658]\n",
      " [1.7711291]\n",
      " [2.575596 ]\n",
      " [2.5335667]\n",
      " [1.0992385]\n",
      " [1.5130072]]\n",
      "74 Cost:  5.0941706 \n",
      "Prediction:\n",
      " [[3.7030199]\n",
      " [4.4871397]\n",
      " [3.1990738]\n",
      " [1.7710588]\n",
      " [2.5755124]\n",
      " [2.5334857]\n",
      " [1.0991844]\n",
      " [1.5129533]]\n",
      "75 Cost:  5.0937915 \n",
      "Prediction:\n",
      " [[3.702907 ]\n",
      " [4.4870286]\n",
      " [3.198982 ]\n",
      " [1.7709883]\n",
      " [2.5754285]\n",
      " [2.5334044]\n",
      " [1.0991303]\n",
      " [1.5128995]]\n",
      "76 Cost:  5.0934134 \n",
      "Prediction:\n",
      " [[3.702795 ]\n",
      " [4.4869175]\n",
      " [3.1988902]\n",
      " [1.7709179]\n",
      " [2.5753448]\n",
      " [2.5333235]\n",
      " [1.099076 ]\n",
      " [1.5128455]]\n",
      "77 Cost:  5.0930357 \n",
      "Prediction:\n",
      " [[3.7026823]\n",
      " [4.486807 ]\n",
      " [3.1987982]\n",
      " [1.7708474]\n",
      " [2.5752609]\n",
      " [2.5332425]\n",
      " [1.0990219]\n",
      " [1.5127918]]\n",
      "78 Cost:  5.092658 \n",
      "Prediction:\n",
      " [[3.7025702]\n",
      " [4.486696 ]\n",
      " [3.1987066]\n",
      " [1.7707771]\n",
      " [2.5751772]\n",
      " [2.5331616]\n",
      " [1.0989678]\n",
      " [1.5127379]]\n",
      "79 Cost:  5.0922804 \n",
      "Prediction:\n",
      " [[3.7024574]\n",
      " [4.4865856]\n",
      " [3.1986146]\n",
      " [1.7707067]\n",
      " [2.5750933]\n",
      " [2.5330806]\n",
      " [1.0989138]\n",
      " [1.512684 ]]\n",
      "80 Cost:  5.0919027 \n",
      "Prediction:\n",
      " [[3.7023454]\n",
      " [4.4864745]\n",
      " [3.198523 ]\n",
      " [1.7706363]\n",
      " [2.5750096]\n",
      " [2.5329998]\n",
      " [1.0988597]\n",
      " [1.5126302]]\n",
      "81 Cost:  5.0915246 \n",
      "Prediction:\n",
      " [[3.7022326]\n",
      " [4.4863634]\n",
      " [3.198431 ]\n",
      " [1.7705659]\n",
      " [2.574926 ]\n",
      " [2.5329187]\n",
      " [1.0988055]\n",
      " [1.5125763]]\n",
      "82 Cost:  5.0911474 \n",
      "Prediction:\n",
      " [[3.7021205]\n",
      " [4.4862523]\n",
      " [3.1983395]\n",
      " [1.7704954]\n",
      " [2.5748422]\n",
      " [2.5328376]\n",
      " [1.0987514]\n",
      " [1.5125226]]\n",
      "83 Cost:  5.090769 \n",
      "Prediction:\n",
      " [[3.7020078]\n",
      " [4.4861417]\n",
      " [3.1982474]\n",
      " [1.770425 ]\n",
      " [2.574758 ]\n",
      " [2.5327566]\n",
      " [1.0986973]\n",
      " [1.5124687]]\n",
      "84 Cost:  5.0903916 \n",
      "Prediction:\n",
      " [[3.7018957]\n",
      " [4.4860306]\n",
      " [3.1981556]\n",
      " [1.7703545]\n",
      " [2.5746746]\n",
      " [2.5326757]\n",
      " [1.0986433]\n",
      " [1.5124148]]\n",
      "85 Cost:  5.0900135 \n",
      "Prediction:\n",
      " [[3.701783 ]\n",
      " [4.4859204]\n",
      " [3.1980639]\n",
      " [1.7702842]\n",
      " [2.5745907]\n",
      " [2.532595 ]\n",
      " [1.0985891]\n",
      " [1.512361 ]]\n",
      "86 Cost:  5.0896363 \n",
      "Prediction:\n",
      " [[3.701671 ]\n",
      " [4.4858093]\n",
      " [3.197972 ]\n",
      " [1.7702138]\n",
      " [2.574507 ]\n",
      " [2.5325139]\n",
      " [1.0985351]\n",
      " [1.5123073]]\n",
      "87 Cost:  5.089258 \n",
      "Prediction:\n",
      " [[3.701558 ]\n",
      " [4.4856987]\n",
      " [3.1978798]\n",
      " [1.7701434]\n",
      " [2.574423 ]\n",
      " [2.5324328]\n",
      " [1.0984809]\n",
      " [1.5122534]]\n",
      "88 Cost:  5.088881 \n",
      "Prediction:\n",
      " [[3.701446 ]\n",
      " [4.4855876]\n",
      " [3.1977882]\n",
      " [1.7700729]\n",
      " [2.5743394]\n",
      " [2.532352 ]\n",
      " [1.0984268]\n",
      " [1.5121995]]\n",
      "89 Cost:  5.0885024 \n",
      "Prediction:\n",
      " [[3.7013333]\n",
      " [4.4854765]\n",
      " [3.1976962]\n",
      " [1.7700026]\n",
      " [2.5742555]\n",
      " [2.5322707]\n",
      " [1.0983727]\n",
      " [1.5121458]]\n",
      "90 Cost:  5.088125 \n",
      "Prediction:\n",
      " [[3.7012212]\n",
      " [4.4853654]\n",
      " [3.1976047]\n",
      " [1.7699322]\n",
      " [2.5741718]\n",
      " [2.5321898]\n",
      " [1.0983187]\n",
      " [1.5120919]]\n",
      "91 Cost:  5.087747 \n",
      "Prediction:\n",
      " [[3.7011085]\n",
      " [4.4852552]\n",
      " [3.1975126]\n",
      " [1.7698617]\n",
      " [2.5740879]\n",
      " [2.5321088]\n",
      " [1.0982646]\n",
      " [1.512038 ]]\n",
      "92 Cost:  5.08737 \n",
      "Prediction:\n",
      " [[3.7009964]\n",
      " [4.485144 ]\n",
      " [3.197421 ]\n",
      " [1.7697914]\n",
      " [2.5740042]\n",
      " [2.532028 ]\n",
      " [1.0982105]\n",
      " [1.5119842]]\n",
      "93 Cost:  5.0869923 \n",
      "Prediction:\n",
      " [[3.7008836]\n",
      " [4.4850335]\n",
      " [3.197329 ]\n",
      " [1.769721 ]\n",
      " [2.5739205]\n",
      " [2.531947 ]\n",
      " [1.0981563]\n",
      " [1.5119305]]\n",
      "94 Cost:  5.086615 \n",
      "Prediction:\n",
      " [[3.7007716]\n",
      " [4.4849224]\n",
      " [3.1972373]\n",
      " [1.7696506]\n",
      " [2.5738368]\n",
      " [2.531866 ]\n",
      " [1.0981022]\n",
      " [1.5118766]]\n",
      "95 Cost:  5.086238 \n",
      "Prediction:\n",
      " [[3.7006588]\n",
      " [4.4848123]\n",
      " [3.1971455]\n",
      " [1.7695801]\n",
      " [2.5737529]\n",
      " [2.531785 ]\n",
      " [1.0980482]\n",
      " [1.5118227]]\n",
      "96 Cost:  5.08586 \n",
      "Prediction:\n",
      " [[3.7005467]\n",
      " [4.4847007]\n",
      " [3.1970537]\n",
      " [1.7695097]\n",
      " [2.5736692]\n",
      " [2.5317042]\n",
      " [1.0979941]\n",
      " [1.5117689]]\n",
      "97 Cost:  5.0854816 \n",
      "Prediction:\n",
      " [[3.700434 ]\n",
      " [4.48459  ]\n",
      " [3.1969616]\n",
      " [1.7694395]\n",
      " [2.5735853]\n",
      " [2.5316231]\n",
      " [1.09794  ]\n",
      " [1.5117152]]\n",
      "98 Cost:  5.0851054 \n",
      "Prediction:\n",
      " [[3.700322 ]\n",
      " [4.4844794]\n",
      " [3.19687  ]\n",
      " [1.7693691]\n",
      " [2.5735018]\n",
      " [2.5315423]\n",
      " [1.097886 ]\n",
      " [1.5116614]]\n",
      "99 Cost:  5.0847273 \n",
      "Prediction:\n",
      " [[3.7002091]\n",
      " [4.4843683]\n",
      " [3.1967783]\n",
      " [1.7692987]\n",
      " [2.5734181]\n",
      " [2.5314612]\n",
      " [1.0978318]\n",
      " [1.5116075]]\n",
      "100 Cost:  5.08435 \n",
      "Prediction:\n",
      " [[3.700097 ]\n",
      " [4.4842577]\n",
      " [3.1966865]\n",
      " [1.7692282]\n",
      " [2.5733342]\n",
      " [2.5313802]\n",
      " [1.0977778]\n",
      " [1.5115538]]\n"
     ]
    }
   ],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "xy = MinMaxScaler(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
