{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 complex, wide, deep 하게 그릴때 그래프를 볼 수가 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 Loss나 Hypothesis 를 직접 찍었음. <br>\n",
    "Step에 따른 Loss를 볼 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are just five steps to use TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. From TF graph, decide which tensors you want to log\n",
    "\n",
    "먼저 어떤 값을 로깅할지를 정함.<br>\n",
    "\n",
    "w2_hist = tf.summary.histogram(\"weights2\", W2)<br>\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Merge All Summaries\n",
    "\n",
    "summary= tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create writer and add graph\n",
    "세션에 들어가서 서머리를 어디에 기록할 것인지를 남김.<br>\n",
    "\n",
    "writer = tf.summary.FileWriter('s/logs')<br>\n",
    "writer.add_graph(sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run summary merge and add_summary\n",
    "\n",
    "s, _ = sess.run([summary, optimizer], feed_dict = feed_dict)<br>\n",
    "writer.add_summary(s, global_step = gloabal_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. Launch TensorBoard\n",
    "터미널 가서 \n",
    "tensorboard --logdir=./logs\n",
    "\n",
    "<br>\n",
    "http://127.0.0.1:6006\n",
    "<br>\n",
    "으로 들어가면 있음.\n",
    "\n",
    "<br> \n",
    "**Tip**<br>\n",
    "local> ssh -L local_port:127.0.0.1:6006 username@server.com<br>\n",
    "server> tensorboard -logdir=./logs/xor_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 어떤 것을 Logging 할 것인가?\n",
    "\n",
    "데이터에 따라 다름<br>\n",
    "cost 같은 just scalar값이면<br>\n",
    "cost_summ = tf.summary.scalar(\"cost\", cost)<br><br>\n",
    "\n",
    "만약 값이 하나의 값이 아닌 여러개의 값을 가진다면?<br>\n",
    "w2_hist = tf.summary.histogram(\"weights2\", W2)<br>\n",
    "b2_hist = tf.summary.histogram(\"biases2\", b2)<br>\n",
    "hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)<br>\n",
    "이렇게 하면 히스토그램을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph를 보고 싶다면?\n",
    "그래프를 한꺼번에 쫙 펼쳐 놓으면 그래프 보기가 힘듬. \n",
    "name_scope라는 걸이용해서 계층별로 정리할수가 있음. \n",
    "\n",
    "\n",
    "\n",
    "<code>\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    w1_hist = tf.summary.histogram(\"weights1\", W1)\n",
    "    b1_hist = tf.summary.histogram(\"biases1\", b1)\n",
    "    layer1_hist = tf.summary.histogram(\"layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    w2_hist = tf.summary.histogram(\"weights2\", W2)\n",
    "    b2_hist = tf.summary.histogram(\"biases2\", b2)\n",
    "    hypothesis_hist = tf.summary.histogram(\"hypothesis\", hypothesis)\n",
    "\n",
    "\n",
    "</code>\n",
    "\n",
    "\n",
    "이렇게 하면 레이어 별로 나눠서 보기 쉽게 해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi runs \n",
    "ex) learning_rate 바꾸면서 확인 해보고 싶을때 <br>\n",
    "\n",
    "<code>\n",
    "tensorboard -logdir =./logs/xor_logs\n",
    "train=tf.train.Gra...........(learning_rate=0.1).minimize(cost)\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs\")\n",
    "\n",
    "tensorbaord -logsdir=./logs/xorlogs_r0_01\n",
    "train=tf.train.Gra...........(learning_rate=0.1).minimize(cost)\n",
    "writer = tf.summary.FileWriter(\"./logs/xor_logs_r0_01\")\n",
    "</code><br><br>\n",
    "학습을 할 때, a를 두고 write부분에서 디렉토리를 다르게 줌.<br>\n",
    "logs/안에 디렉토리를 여러개 만드는 것.<br>\n",
    "이렇게 해놓고 여러번 실행 시킴<br>\n",
    "\n",
    "그 후에 각각의 디렉토리를 가지고 실행시키지 않고 parent디렉토리를 가지고 tensorboard실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
