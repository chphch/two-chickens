{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dirname = os.getcwd()\n",
    "\n",
    "file_path_train = '../dataset_kor_OSX/traffic-accident-data.csv'\n",
    "file_path_predict = '../test_kor_OSX.csv'\n",
    "\n",
    "dropping_columns_train = [\n",
    "    '발생년', '발생년월일시', '발생분', '사상자수',\n",
    "    '사고유형', '법규위반_대분류', '당사자종별_1당', '당사자종별_2당',\n",
    "    '발생위치X_UTMK', '발생위치Y_UTMK', '경도', '위도']\n",
    "dropping_columns_predict = ['사상자수']\n",
    "merging_columns_map = {\n",
    "    '발생지': ['발생지시도', '발생지시군구'],\n",
    "    '사고유형': ['사고유형_대분류', '사고유형_중분류'],\n",
    "    '도로형태': ['도로형태_대분류', '도로형태'],\n",
    "}\n",
    "numerical_columns = ['사망자수', '중상자수', '경상자수', '부상신고자수']\n",
    "\n",
    "def read_file(file_path):\n",
    "    full_path = os.path.join(dirname, file_path)\n",
    "    return pd.read_csv(full_path)\n",
    "\n",
    "def drop(original, dropping_columns):\n",
    "    return original.drop(dropping_columns, axis=1)\n",
    "\n",
    "def merge(dropped):\n",
    "    mergeds = [dropped.reindex(columns, axis='columns')\n",
    "       .apply(lambda s: s.str.cat(sep='-'), axis=1)\n",
    "       .replace('', np.nan)\n",
    "       .rename(name)\n",
    "     for name, columns in merging_columns_map.items()]\n",
    "    merging_columns = [merging_column\n",
    "        for merging_columns in merging_columns_map.values()\n",
    "        for merging_column in merging_columns]\n",
    "    not_merged = dropped.drop(merging_columns, axis='columns')\n",
    "    return pd.concat(mergeds + [not_merged], axis=1)\n",
    "\n",
    "def one_hot_encode(df, one_hot_encode_map):\n",
    "    one_hot_encoded_columns = []\n",
    "    for column in df:\n",
    "        series = df.loc[:, column]        \n",
    "        one_hot_encoded_column = pd.get_dummies(series).rename(columns=one_hot_encode_map[column])    \n",
    "        one_hot_encoded_columns.append(one_hot_encoded_column)\n",
    "    return pd.concat(one_hot_encoded_columns, axis=1, sort=False)\n",
    "\n",
    "vectorize = np.vectorize(lambda value, columns: int(value in columns))\n",
    "\n",
    "def one_hot_encode_for_predict(series, categorize_map, one_hot_encode_map):\n",
    "    one_hot_encoded_columns = []\n",
    "    for column, value in series.items():\n",
    "        vector = vectorize(value, categorize_map[column])\n",
    "        one_hot_encoded_column = pd.Series(\n",
    "            dict(zip(categorize_map[column], vector))\n",
    "        ).rename(one_hot_encode_map[column])\n",
    "        one_hot_encoded_columns.append(one_hot_encoded_column)\n",
    "    return pd.concat(one_hot_encoded_columns)\n",
    "\n",
    "def categorize_column(series):\n",
    "    cat = series.astype('category').cat\n",
    "    return cat.codes, cat.categories\n",
    "\n",
    "def filter_numerical(df):\n",
    "    return df.reindex(df.columns[df.columns.isin(numerical_columns)], axis='columns')\n",
    "\n",
    "def filter_categorical(df):\n",
    "    return df.reindex(df.columns[~df.columns.isin(numerical_columns)], axis='columns')\n",
    "\n",
    "def drop_index(series, dropping_columns):\n",
    "    return series[~series.index.isin(dropping_columns)]\n",
    "\n",
    "def filter_index(series, filtering_columns):\n",
    "    return series[series.index.isin(filtering_columns)]\n",
    "\n",
    "def filter_row_numerical(series):\n",
    "    return filter_index(series, numerical_columns)\n",
    "\n",
    "def filter_row_categorical(series):\n",
    "    return drop_index(series, numerical_columns)\n",
    "\n",
    "def nan_columns(series):\n",
    "    return series[series.isna()].index\n",
    "    \n",
    "Condition = namedtuple('Condition', ['original', 'preprocessed', 'target_columns'])\n",
    "\n",
    "class Preprocessor(object):\n",
    "    def __init__(self):\n",
    "        self.numerical = pd.DataFrame()\n",
    "        self.categorical = pd.DataFrame()\n",
    "        self.categorized = pd.DataFrame()\n",
    "        self.categorize_map = {}\n",
    "        self.conditions = []\n",
    "        self.predict_columns_order = pd.Index([])\n",
    "        \n",
    "        self.preprocess()\n",
    "        self.generate_conditions()\n",
    "\n",
    "    def categorize(self):\n",
    "        categorized_columns = []\n",
    "        for column in self.categorical:\n",
    "            categorize_coded, categorize_map = categorize_column(\n",
    "                self.categorical.loc[:, column])\n",
    "            categorized_columns.append(categorize_coded)\n",
    "            self.categorize_map[column] = categorize_map\n",
    "        self.categorized =  pd.concat(categorized_columns, axis=1, sort=False)\n",
    "        \n",
    "    def preprocess(self):\n",
    "        original = read_file(file_path_train)\n",
    "        dropped = drop(original, dropping_columns_train)\n",
    "#         merged = merge(dropped)\n",
    "        self.numerical = filter_numerical(dropped)\n",
    "        self.categorical = filter_categorical(dropped)\n",
    "        self.categorize()\n",
    "        \n",
    "    def generate_conditions(self):\n",
    "        original = read_file(file_path_predict)\n",
    "        self.predict_columns_order = original.columns\n",
    "        dropped = drop(original, dropping_columns_predict)\n",
    "#         merged = merge(dropped)\n",
    "        for index in dropped.index:\n",
    "            row = dropped.loc[index]\n",
    "            numerical = filter_row_numerical(row)\n",
    "            categorical = filter_row_categorical(row)\n",
    "\n",
    "            numerical_target_columns = nan_columns(numerical)\n",
    "            categorical_target_columns = nan_columns(categorical)\n",
    "            target_columns = numerical_target_columns.append(categorical_target_columns)\n",
    "\n",
    "            numerical_dropped = drop_index(numerical, numerical_target_columns)\n",
    "            categorical_dropped = drop_index(categorical, categorical_target_columns)\n",
    "            one_hot_encoded = one_hot_encode_for_predict(\n",
    "                categorical_dropped,\n",
    "                categorize_map=self.categorize_map,\n",
    "                one_hot_encode_map=self.one_hot_encode_map)\n",
    "            \n",
    "            preprocessed = numerical_dropped.append(one_hot_encoded)\n",
    "            condition = Condition(\n",
    "                original=original.loc[index],\n",
    "                preprocessed=preprocessed,\n",
    "                target_columns=target_columns)\n",
    "            self.conditions.append(condition)\n",
    "        \n",
    "    def preprocessed(self, target_column, dropping_columns):\n",
    "        dropping_columns = pd.Index(list(dropping_columns) + [target_column])\n",
    "        numerical_dropping_columns = filter(\n",
    "            lambda x: x in numerical_columns, dropping_columns)\n",
    "        categorical_dropping_columns = filter(\n",
    "            lambda x: x not in numerical_columns, dropping_columns)\n",
    "        dropped_numerical = self.numerical.drop(\n",
    "                            columns=numerical_dropping_columns)\n",
    "        dropped_categorical = self.categorical.drop(\n",
    "                              columns=categorical_dropping_columns)\n",
    "        dropped_one_hot_encoded = one_hot_encode(\n",
    "            dropped_categorical, self.one_hot_encode_map)\n",
    "        X = pd.concat([dropped_numerical, dropped_one_hot_encoded],\n",
    "                      axis='columns', sort=False)\n",
    "        y = (self.numerical.loc[:, target_column]\n",
    "             if target_column in numerical_columns\n",
    "             else self.categorical.loc[:, target_column])\n",
    "        return X, y\n",
    "    \n",
    "    @property\n",
    "    def one_hot_encode_map(self):\n",
    "        return dict((category, dict(\n",
    "                            (value, '.'.join([category, value])) for value in values))\n",
    "                    for category, values in self.categorize_map.items())\n",
    "    \n",
    "    @property\n",
    "    def category_vectorizing_map(self):\n",
    "        return dict(\n",
    "            (category, dict((v, k)\n",
    "                            for k, v in enumerate(indices)))\n",
    "            for category, indices in self.categorize_map.items())\n",
    "    \n",
    "    def category_vectorize(self, categorical_data):\n",
    "        return pd.Series(\n",
    "                dict((category, self.category_vectorizing_map[category][value])\n",
    "                     for category, value in categorical_data.items())\n",
    "            )\n",
    "    \n",
    "#     @property\n",
    "#     def reverse_category_vectorizing_map(self):\n",
    "#         return dict((k, dict(enumerate(v))) for k, v in preprocessor.categorize_map.items())\n",
    "            \n",
    "#     def restore_predicted(self, predicted):\n",
    "#         numerical = filter_row_numerical(predicted)\n",
    "#         categorical = filter_row_categorical(predicted)\n",
    "#         decoded_key_value = {}\n",
    "#         for k, v in categorical.items():\n",
    "#             decoded_value = self.reverse_category_vectorizing_map[k][v]\n",
    "#             decoded_key_value[k] = decoded_value\n",
    "#             if k in merging_columns_map:\n",
    "#                 unmerged_values = decoded_value.split('-')\n",
    "#                 unmerged_columns = merging_columns_map[k]\n",
    "#                 for unmerged_key, unmerged_value in zip(unmerged_columns, unmerged_values):\n",
    "#                     decoded_key_value[unmerged_key] = unmerged_value\n",
    "#             else:\n",
    "#                 decoded_key_value[k] = decoded_value\n",
    "#         decoded = pd.Series(decoded_key_value)\n",
    "#         return numerical.append(decoded)\n",
    "\n",
    "preprocessor = Preprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
